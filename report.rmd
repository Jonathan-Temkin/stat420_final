---
Author:  RandomM53
output:
  html_document:
    theme: readable
    toc: true
  pdf_document: default
title: Factors Impacting Life Expectancy
urlcolor: cyan
editor_options: 
  markdown: 
    wrap: 72
---

# Introduction

This project will research factors that might predict life expectancy
across multiple regions globally. It is generally accepted that
developed countries have lower mortality and higher lifespan than their
less-developed peers. But how true is this assumption? And if these
countries do indeed have lower mortality, which factors are most
responsible?

Developed countries tend to have more resources, better nutrition
standards and access to advanced medical infrastructure, all of which
facilitate longevity. However, it shouldn't be assumed that all aspects
of development are positive. Many developed countries are more likely to
suffer from higher rates of obesity or alcoholism, counteracting their
advantages in nutrition and medicine. Moreover, the complex economies of
developed countries may result in more stressful lifestyles, further
harming mortality.

Buddhist monks live in Nepal don't spend their sleeping time on swiping
phones, breath car exhaust, or eat packaged food full of chemicals. It's
true Nepal's GDP is far behind US, but do US residents live longer than
Nepal people necessarily? Hopefully data analysis with this data set can
shed some light.

## Setup

```{r}
# Set default CRAN mirror and install required packages
options(repos = c(CRAN = "https://cloud.r-project.org"))

required_packages <- c("tseries", "lmtest", "car", "glmnet", "caret", "readr", "knitr")
new_packages <- required_packages[!(required_packages %in% installed.packages()[,"Package"])]
if (length(new_packages)) install.packages(new_packages, dependencies = TRUE)
```

## Description of the data set

For this project we propose using the `Life Expectancy (WHO)` data set
which is available
[here](https://www.kaggle.com/datasets/kumarajarshi/life-expectancy-who).
The data is an amalgamation of two sources. The primary source is The
Global Health Observatory (GHO) repository, which is maintained by the
World Health Organization (WHO) for the purpose of tracking demographic
and health factors impacting mortality. The data spans 193 countries and
15 years, from 2000 to 2015. This dataset is supplemented with United
Nations economic data. The resulting dataset will enable us to assess
the impact of immunization, economic and social factors on mortality.

The dataset was compiled by Deeksha Russel and Duan Wang. It is a
curated subset of the Global Health Observatory database, with only
those variables deemed most critical and representative being retained
in the file dataset. The dataset has also been cleaned to remove
countries for which data was incomplete.

```{r}
library(readr)
data = read_csv('./data/life_expectancy.csv', show_col_types = FALSE)
head(data)
```

There are 22 columns and 2938 records in the CSV file. `Life expectancy`
will be used as the response variable, and the rest are predictor
candidates.


| Name                   | Definition                                                                                             |
|---------------------|---------------------------------------------------|
| country                | country                                                                                                |
| year                   | year                                                                                                   |
| status                 | Developed or Developing                                                                                |
| life expectancy        | life expectancy in age                                                                                 |
| adult mortality        | Adult Mortality Rates of both sexes (probability of dying between 15 and 60 years per 1000 population) |
| infant deaths          | Number of Infant Deaths per 1000 population                                                            |
| alcohol                | Alcohol, recorded per capita (15+) consumption (in litres of pure alcohol)                             |
| percentage expenditure | Expenditure on health as a percentage of Gross Domestic Product per capita (%)                         |
| Hepatitis B            | Hepatitis B (HepB) immunization coverage among 1-year-olds (%)                                         |
| Measles                | Measles - number of reported cases per 1000 population                                                 |
| BMI                    | Average Body Mass Index of entire population                                                           |
| under-five deaths      | Number of under-five deaths per 1000 population                                                        |
| Polio                  | Polio (Pol3) immunization coverage among 1-year-old (%)                                                |
| total expenditure      | General government expenditure on health as a percentage of total government expenditure (%)           |
| Diphtheria             | Diphtheria tetanus toxoid and pertussis (DTP3) immunization coverage among 1-year-olds (%)             |
| HIV/AIDS               | Deaths per 1 000 live births HIV/AIDS (0-4 years)                                                      |
| GDP                    | Gross Domestic Product per capita (in USD)                                                             |
| Population             | Population of the country                                                                              |
| thinness 1-19 years    | Prevalence of thinness among children and adolescents for Age 10 to 19 (% )                            |
| thinness 5-9 years     | Prevalence of thinness among children for Age 5 to 9(%)                                                |
| income composition     | Human Development Index in terms of income composition of resources (index ranging from 0 to 1)        |
| schooling              | Number of years of Schooling(years)                                                                    |

# Methods

## Data Cleaning

Original variable names are not r-friendly. We will rename them to
follow snake case for easy access on further analysis.

-   rename variables
-   convert category variables to factors
-   filter records based on column values
-   omit NA values

```{r}
names(data)[names(data) == "Country"] = "country"
names(data)[names(data) == "Year"] = "year"
names(data)[names(data) == "Status"] = "status"
names(data)[names(data) == "Life expectancy"] = "life_expectancy"
names(data)[names(data) == "Adult Mortality"] = "adult_mortality"
names(data)[names(data) == "infant deaths"] = "infant_deaths"
names(data)[names(data) == "Alcohol"] = "alcohol"
names(data)[names(data) == "percentage expenditure"] = "percent_exp"
names(data)[names(data) == "Hepatitis B"] = "hepatitis"
names(data)[names(data) == "measles"] = "measles"
names(data)[names(data) == "under-five deaths"] = "under_5_deaths"
names(data)[names(data) == "Polio"] = "polio"
names(data)[names(data) == "Total expenditure"] = "total_exp"
names(data)[names(data) == "Diphtheria"] = "diphtheria"
names(data)[names(data) == "HIV/AIDS"] = "hiv_aids"
names(data)[names(data) == "Population"] = "population"
names(data)[names(data) == "thinness  1-19 years"] = "thinness_1_19"
names(data)[names(data) == "thinness 5-9 years"] = "thinness_5_9"
names(data)[names(data) == "Income composition of resources"] = "HBI"
names(data)[names(data) == "Schooling"] = "schooling"

data$country = as.factor(data$country)
data$year = as.factor(data$year)
data$status = as.factor(data$status)

data = subset(data, percent_exp > 0)
data = subset(data, hiv_aids > 0)
data = subset(data, GDP > 0)
data = na.omit(data)
```

## Identify Potential Transformations and Collinearity

For this analysis we intend to perform linear regression with multiple
predictors. However, we need to verify that our predictors are
independent, which is a core assumption of the linear regression model.
If multiple predictors in our model are correlated, it will harm our
ability to determine the impact of each predictor on the response
variable, since any change to the collinear predictors will exert an
outsized influence on the response variable. Collinear variables will
also increase error and reduce the predictive power of the model.

First, we can assess the data visually by creating a matrix of
scatterplots to check the shapes of curves for

-   `life_expectancy vs numeric predictors`

-   $Predictor_x$ vs $Predictor_y$

Using the pairs function, we can plot all possible scatterplots between
pairs of response and predictor variables in the dataset.

```{r}
data_numeric_only = subset(data, select = -c(country, year, status))
pairs(data_numeric_only)
```

From above matrix of scatterplots, we can observe

-   collinearity

    -   `infant_death` and `under_5_death`

    -   `thinness_5_9` and `thinness_1_19`

-   predictors with non-linear shape of curve against life expectancy

    -   `percent_exp`

    -   `hiv_aids`

    -   `GDP`

Take logarithm for predictors with non-linear shape of curve

```{r}
data_transformed = data.frame(data)
data_transformed["log_percent_exp"] = log(data_transformed$percent_exp)
data_transformed["log_hiv_aids"] = log(data_transformed$hiv_aids)
data_transformed["log_GDP"] = log(data_transformed$GDP)
```

Additionally, we can employ a numerical methodology to further check for
collinearity. We can do this by using the cor() function to check for
all pairwise correlations between numerical variables in the dataset.

```{r}
var_cors = round(cor(data_numeric_only), 2)
var_cors
```

This analysis can be further refined to identify the variable pairs with
the highest correlations. This will enable us to detect significant
collinearities with the potential to undermine our model.

```{r}
var_cors_df = as.data.frame(as.table(var_cors))
var_cors_df_ordered = var_cors_df[order(var_cors_df$Freq, decreasing = TRUE), ]
var_cors_df_ordered = subset(var_cors_df_ordered, var_cors_df_ordered$Var1 != var_cors_df_ordered$Var2)
var_cors_df_ordered = subset(var_cors_df_ordered, (var_cors_df_ordered$Var1 != "life_expectancy" & var_cors_df_ordered$Var2 != "life_expectancy"))
colnames(var_cors_df_ordered) = c("response1", "response2", "cor")
var_cors_df_ordered
```

From the above, it is evident that many of the predictor pairs in our
model exhibit collinearity. This is a result of many variables in the
dataset having some level of overlap -- such as under 5 deaths and
infant deaths. We will avoid using these concurrently in the model.

Next, we can search for evidence of collinearity by examining some of
the coefficient parameters of the complete additive model.

```{r}
predictors = names(data)
num_predictors = length(predictors)
results = rep(0, num_predictors)
for (i in 1:num_predictors) {
  predictor = predictors[i]
  temp_analysis_model = as.formula(paste("life_expectancy ~ . -", predictor))
  temp_analysis_model = lm(temp_analysis_model, data = data)                      
  r_squared = summary(temp_analysis_model)$r.squared
  results[i] = r_squared
}
results_df = data.frame(
  var = predictors,
  result = results
)
results_df = results_df[order(results_df$result, decreasing = TRUE),]
results_df
```

Finally, we can calculate VIF (variance inflation factor) for each
parameter of the model. VIF is a useful measure for assesing
collinearity because it attempts to isolate the impact of collinearity
on model variance. VIF greater than 5 generally indicates the presence
of collinearity

```{r}
library(car)
fit_add_orign = lm(life_expectancy ~ ., data = subset(data, select = -c(country, year)))
vif_reuslts_table = data.frame(as.table(vif(fit_add_orign)))
colnames(vif_reuslts_table) = c("predictor", "VIF")
vif_reuslts_table
```

We want to mitigate the impact of collinearity on our model by removing
linearly correlated columns `thinness_5_9` and `infant_death` because
they are subsets to `thiness_1_19` and `under_5_deaths` respectively.
`GDP` and `percent_exp` also have VIF greater than 5, but there isn't a
clear subset relationship between them. We will keep them in data set
and rely on step wise variable selection to decide which to pick. Two
category columns `country` and `year` are removed also to get rid of
time series characteristic and mitigate geographic influence.

```{r}
data_cleaned = subset(data_transformed, select = -c(country, year, percent_exp, hiv_aids, GDP, thinness_5_9, infant_deaths))
data_cleaned = na.omit(data_cleaned)
```

## Model Selection

### compare additive models with predictors and transformed predictors

```{r}
fit_add_orign = lm(life_expectancy ~ ., data = subset(data, select = -c(country, year)))
summary(fit_add_orign)
fit_add_trans = lm(life_expectancy ~ ., data = data_cleaned)
summary(fit_add_trans)
```

Both models are significant under 0.01 significant level, and the one
with transformed data has higher `r-squared` value. Further optimization
will be based the data set `data_cleaned`.

### perform a regression with level 2 interaction

```{r}
fit_int = lm(life_expectancy ~ .^2, data = data_cleaned)
```

### compare the interaction model with additive model

```{r}
anova(fit_add_trans, fit_int)
```

`p-value` is small enough to reject the hypothesis that interactive
predictors were in-significant, hence interactive model `fit_int` is
preferred over the additive one.

### backward step-wise selection with AIC on interactive model

```{r}
fit_selected = step(fit_int, direction = "backward", trace = 0)
summary(fit_selected)
```

Noticed that not all selected predictors are significant with a high
significance level such as 99%. Try to fit a simple model which excludes
predictors with `p-value > 0.01`

```{r}
df_coef = data.frame(summary(fit_selected)$coefficients)
row.names(df_coef)[df_coef["Pr...t.."] < 0.01]
(predictor_formula_str = paste(row.names(df_coef)[df_coef["Pr...t.."] < 0.01][-1], collapse = " + "))
fit_small = lm(life_expectancy ~ adult_mortality + Measles + BMI + polio + total_exp + population + thinness_1_19 + HBI + log_hiv_aids + status:adult_mortality + status:hepatitis + status:total_exp + status:thinness_1_19 + status:HBI + status:schooling + adult_mortality:BMI + adult_mortality:schooling + adult_mortality:log_hiv_aids + adult_mortality:log_GDP + alcohol:hepatitis + alcohol:Measles + alcohol:log_percent_exp + alcohol:log_hiv_aids + hepatitis:total_exp + hepatitis:log_percent_exp + BMI:population + BMI:thinness_1_19 + BMI:schooling + under_5_deaths:polio + under_5_deaths:HBI + under_5_deaths:schooling + polio:HBI + total_exp:thinness_1_19 + total_exp:HBI + diphtheria:HBI + diphtheria:schooling + thinness_1_19:HBI + thinness_1_19:schooling + thinness_1_19:log_hiv_aids + HBI:schooling + HBI:log_hiv_aids + schooling:log_percent_exp + schooling:log_GDP + log_percent_exp:log_GDP,
               data = data_cleaned)
anova(fit_small, fit_selected)
```

`fit_selected` is preferred over the smaller model on anova analysis,
but how about the Test-Train Split?

```{r, warning=FALSE}
set.seed(233)
total = nrow(data_cleaned)
trn_idx = sample(total, floor(total * 0.8))
data_trn = data_cleaned[trn_idx, ]
data_tst = data_cleaned[-trn_idx, ]

rmse <- function(model, new_data) {
  y_hat = predict(model, newdata = new_data)
  return(sqrt(mean((y_hat - data_tst$life_expectancy)^2)))
}

fit_complex = lm(life_expectancy ~ status + adult_mortality + alcohol + hepatitis + 
    Measles + BMI + under_5_deaths + polio + total_exp + diphtheria + 
    population + thinness_1_19 + HBI + schooling + log_percent_exp + 
    log_hiv_aids + log_GDP + status:adult_mortality + status:alcohol + 
    status:hepatitis + status:BMI + status:total_exp + status:thinness_1_19 + 
    status:HBI + status:schooling + adult_mortality:BMI + adult_mortality:population + 
    adult_mortality:schooling + adult_mortality:log_hiv_aids + 
    adult_mortality:log_GDP + alcohol:hepatitis + alcohol:Measles + 
    alcohol:BMI + alcohol:population + alcohol:HBI + alcohol:schooling + 
    alcohol:log_percent_exp + alcohol:log_hiv_aids + hepatitis:Measles + 
    hepatitis:total_exp + hepatitis:population + hepatitis:HBI + 
    hepatitis:log_percent_exp + Measles:BMI + Measles:under_5_deaths + 
    Measles:total_exp + Measles:HBI + Measles:log_percent_exp + 
    Measles:log_hiv_aids + Measles:log_GDP + BMI:under_5_deaths + 
    BMI:total_exp + BMI:diphtheria + BMI:population + BMI:thinness_1_19 + 
    BMI:HBI + BMI:schooling + under_5_deaths:polio + under_5_deaths:total_exp + 
    under_5_deaths:population + under_5_deaths:HBI + under_5_deaths:schooling + 
    under_5_deaths:log_percent_exp + under_5_deaths:log_hiv_aids + 
    under_5_deaths:log_GDP + polio:total_exp + polio:population + 
    polio:HBI + total_exp:diphtheria + total_exp:thinness_1_19 + 
    total_exp:HBI + total_exp:log_percent_exp + total_exp:log_GDP + 
    diphtheria:HBI + diphtheria:schooling + diphtheria:log_percent_exp + 
    population:HBI + population:log_percent_exp + population:log_hiv_aids + 
    population:log_GDP + thinness_1_19:HBI + thinness_1_19:schooling + 
    thinness_1_19:log_hiv_aids + thinness_1_19:log_GDP + HBI:schooling + 
    HBI:log_hiv_aids + schooling:log_percent_exp + schooling:log_hiv_aids + 
    schooling:log_GDP + log_percent_exp:log_GDP,
    data = data_trn)
fit_simple = lm(life_expectancy ~ adult_mortality + Measles + BMI + polio + total_exp + 
    population + thinness_1_19 + HBI + log_hiv_aids + status:adult_mortality + 
    status:hepatitis + status:total_exp + status:thinness_1_19 + 
    status:HBI + status:schooling + adult_mortality:BMI + adult_mortality:schooling + 
    adult_mortality:log_hiv_aids + adult_mortality:log_GDP + 
    alcohol:hepatitis + alcohol:Measles + alcohol:log_percent_exp + 
    alcohol:log_hiv_aids + hepatitis:total_exp + hepatitis:log_percent_exp + 
    BMI:population + BMI:thinness_1_19 + BMI:schooling + under_5_deaths:polio + 
    under_5_deaths:HBI + under_5_deaths:schooling + polio:HBI + 
    total_exp:thinness_1_19 + total_exp:HBI + diphtheria:HBI + 
    diphtheria:schooling + thinness_1_19:HBI + thinness_1_19:schooling + 
    thinness_1_19:log_hiv_aids + HBI:schooling + HBI:log_hiv_aids + 
    schooling:log_percent_exp + schooling:log_GDP + log_percent_exp:log_GDP,
    data = data_trn)
trn_rmse_complex = rmse(fit_complex, data_trn)
tst_rmse_complex = rmse(fit_complex, data_tst)
trn_rmse_simple = rmse(fit_simple, data_trn)
tst_rmse_simple = rmse(fit_simple, data_tst)

library(knitr)
kable(data.frame(model = c("Simple", "Complex"),
                 "Train RMSE" = c(trn_rmse_simple, trn_rmse_complex),
                 "Test RMSE" = c(tst_rmse_simple, tst_rmse_complex)))
```

The simple model has lower RMSE on both train and test data sets.

Lets compare the Simple model to the "really simple" additive model that
we originally started out with.

```{r, warning=FALSE}

# Create a model based on the training dataset with the predictors chosen via backward AIC
fit_add = lm(life_expectancy ~ status + adult_mortality + hepatitis + BMI + under_5_deaths + total_exp + diphtheria + population + thinness_1_19 + HBI + schooling + log_percent_exp + log_hiv_aids + log_GDP, data = data_trn)
fit_add_selected = step(fit_add_trans, direction = "backward", trace = 0)

trn_rmse_add = rmse(fit_add_selected, data_trn)
tst_rmse_add = rmse(fit_add_selected, data_tst)

kable(data.frame(model = c("Simple", "Additive"),
                 "Train RMSE" = c(trn_rmse_simple, trn_rmse_add),
                 "Test RMSE" = c(tst_rmse_simple, tst_rmse_add)))   
```

Interestingly, the additive model has lower train RMSE than the simple
interaction model. However, the test RMSE is way lower for the simple
interaction model and thus we continue to prefer the simple interaction
model.

Re-fit the model on the entire data set `data_cleaned`

```{r}
fit_simple = lm(life_expectancy ~ adult_mortality + Measles + BMI + polio + total_exp + 
    population + thinness_1_19 + HBI + log_hiv_aids + status:adult_mortality + 
    status:hepatitis + status:total_exp + status:thinness_1_19 + 
    status:HBI + status:schooling + adult_mortality:BMI + adult_mortality:schooling + 
    adult_mortality:log_hiv_aids + adult_mortality:log_GDP + 
    alcohol:hepatitis + alcohol:Measles + alcohol:log_percent_exp + 
    alcohol:log_hiv_aids + hepatitis:total_exp + hepatitis:log_percent_exp + 
    BMI:population + BMI:thinness_1_19 + BMI:schooling + under_5_deaths:polio + 
    under_5_deaths:HBI + under_5_deaths:schooling + polio:HBI + 
    total_exp:thinness_1_19 + total_exp:HBI + diphtheria:HBI + 
    diphtheria:schooling + thinness_1_19:HBI + thinness_1_19:schooling + 
    thinness_1_19:log_hiv_aids + HBI:schooling + HBI:log_hiv_aids + 
    schooling:log_percent_exp + schooling:log_GDP + log_percent_exp:log_GDP,
    data = data_cleaned)
```

## Model Diagnostics

### Statistical Tests

```{r}
# Statistical Tests
library(lmtest)
bp_simple <- bptest(fit_simple)
shapiro_simple <- shapiro.test(resid(fit_simple))
```

| Test          | Statistic                              | p-value                                             | Conclusion                               |
|------------------|-------------------|------------------|------------------|
| Breusch-Pagan | `r round(bp_simple$statistic, 2)`      | `r format(bp_simple$p.value, scientific=TRUE)`      | Heteroscedasticity: Present if p \< 0.05 |
| Shapiro-Wilk  | `r round(shapiro_simple$statistic, 2)` | `r format(shapiro_simple$p.value, scientific=TRUE)` | Normality: Violated if p \< 0.05         |

-   **Breusch-Pagan Test:** Small `p-value` confirms heteroscedasticity.
-   **Shapiro-Wilk Test:** Significant p-values suggest non-normality.

### Visualize residuals of the selected model

#### Plot the histogram of residuals

```{r}
hist(resid(fit_simple),
     xlab = "Residuals",
     main = "Histogram of Residuals, fit_simple",
     col = "darkorange",
     border = "dodgerblue",
     breaks = 20)
```

The histogram appears reasonably normal counter intuitively. Residuals
seem to distribute evenly around $\mu = 0$.

#### Plot the Q-Q plot

```{r}
qqnorm(resid(fit_simple),
       main = "Normal Q-Q Plot, fit_simple",
       col = "darkgrey")
qqline(resid(fit_simple), col = "dodgerblue", lwd = 2)
```

Q-Q plot shows residuals derivate from normal distribution when
magnitude of quantile is beyond 1.5.

Normally standardized residuals greater than 2 in magnitude should only
happen approximately 5 percent of the time, while 41% of `fit_simple`
standardized residuals are greater than 2.

```{r}
mean(rstandard(fit_simple)[abs(rstandard(fit_simple)) > 2])
```

## Outlier Diagnostics

The Q-Q plot definitely makes it seem that the normality assumptions is
violated. Lets try to remove outliers and see if we can improve the
normality of the residuals.

To check for outlier data points having an outside influence on our
model, we will check the cooks distance of the data in our dataset.

```{r}
# calculating cooks distance for all the data points for the selected simple model that was trained on all the data
simple_int_mod_cd = cooks.distance(fit_simple)
sum(simple_int_mod_cd > 4/length(simple_int_mod_cd))
```

There are 121 outliers that are having a high influence on our model.

Lets remove these and run the diagnostics again.

```{r}
fit_simple_fix = lm(life_expectancy ~ adult_mortality + Measles + BMI + polio + total_exp + 
    population + thinness_1_19 + HBI + log_hiv_aids + status:adult_mortality + 
    status:hepatitis + status:total_exp + status:thinness_1_19 + 
    status:HBI + status:schooling + adult_mortality:BMI + adult_mortality:schooling + 
    adult_mortality:log_hiv_aids + adult_mortality:log_GDP + 
    alcohol:hepatitis + alcohol:Measles + alcohol:log_percent_exp + 
    alcohol:log_hiv_aids + hepatitis:total_exp + hepatitis:log_percent_exp + 
    BMI:population + BMI:thinness_1_19 + BMI:schooling + under_5_deaths:polio + 
    under_5_deaths:HBI + under_5_deaths:schooling + polio:HBI + 
    total_exp:thinness_1_19 + total_exp:HBI + diphtheria:HBI + 
    diphtheria:schooling + thinness_1_19:HBI + thinness_1_19:schooling + 
    thinness_1_19:log_hiv_aids + HBI:schooling + HBI:log_hiv_aids + 
    schooling:log_percent_exp + schooling:log_GDP + log_percent_exp:log_GDP,
    data = data_cleaned,
    subset = simple_int_mod_cd < 4 / length(simple_int_mod_cd))

shapiro.test(resid(fit_simple_fix))
```

```{r}
qqnorm(resid(fit_simple_fix), col = "darkgrey")
qqline(resid(fit_simple_fix), col = "dodgerblue", lwd = 2)
```

We managed to improve the normality of the residuals for the interactive
model. The Q-Q plot looks much better, and the percentage of
standardized residuals beyond 2 is decreased from 41% to 17%.

```{r}
mean(rstandard(fit_simple)[abs(rstandard(fit_simple_fix)) > 2])
```

# Results

We started from additive and interactive model with all numeric
predictors and one dummy variable `status`, then performed step-wise
variable selection, trimmed variables with their `p-value`, and compared
models with `r-squared` and RMSE based on train/test data, and finally
polished the model given issues spotted from model diagnostics. The
selected model has a r squared of 0.92 which is fairly close to 1.

```{r}
summary(fit_simple_fix)$r.squared
```

Based on the selected model, significant factors impact life expectancy
are

```{r}
summary(fit_simple_fix)$coefficients
```

# Discussion

Among above influential factors some are directly related to the
economic status of a country such as `log_GDP` and `HBI`, others are
indirectly related to economy such as `schooling`, `BMI`, and vaccine
coverage (`polio`, `Hepatitis`, and `Measles`). Development level of a
country determines the amount of resources contributed to education
(`schooling`) and health care such as vaccine coverage.

Calculate the expected life expectancy using the selected model and
cleaned data set, then sort the data frame by life expectancy in
descending order.

```{r}
data_predict = data_transformed[!duplicated(data_transformed["country"]),]
data_predict = subset(data_predict, select = -c(life_expectancy))
data_fitted = data.frame(subset(data_predict, select = -c(year, percent_exp, hiv_aids, GDP, thinness_5_9, infant_deaths)))
data_fitted$life_expectancy = predict(fit_simple_fix, newdata = data_predict)
data_fitted = data_fitted[order(data_fitted$life_expectancy, decreasing = TRUE),]
kable(subset(head(data_fitted, 80), select = c(country, status, life_expectancy, log_GDP)))
```

Canada, Israel, and France ranks high in above table and are marked as
developing, but there are no WTO definitions of `developed` and
`developing` countries. Members may announce themselves as developing to
gain tax and trade benefits. It's against our common senses to treat
these three countries equally as Kazakhstan or Uruguay economically. We
can conclude that economic-developed countries have higher life
expectancy than developing ones. Circle back to the question we asked in
introduction about Nepal, the data shows no developed countries have
lower life expectancy than Nepal. Unfortunately materialism defeats
spiritual sanctification again. The selected model still has flaws such
as heteroscedasticity and normality violation. It is definitely not the
perfect answer, but countries and worldwide organizations can utilize it
as a guidance on which areas resources and assets should be allocated in
order to strike for greater longevity for all mankind efficiently.

## Prediction vs Explanation

The model above is most useful for prediction as it has the lowest RMSE when we used the test-train method.

So it would be most fit to use when we had data for a new country but we did not know its life expectancy. We could use the model to predict the life expectancy.

However, for explanation purposes, the extremely simple additive model still works best.

We run an exhaustive search and use the variable selection for the model with each number of predictors to get an idea of importance.

```{r warning=FALSE}
library(leaps)
all_life_mod = summary(regsubsets(life_expectancy ~ ., data = data_cleaned, nvmax = 6))
all_life_mod$which

(best_r2_ind = which.max(all_life_mod$adjr2))
```

Using the analysis above, we can see that if we were limited to a model of n predictors, we would pick the following predictors:


| Rank | Predictor                   |
|------|-----------------------------|
| 1    | HIV/Aids deaths per 100     |
| 2    | Hepatitis Immunization      |
| 3    | Schooling                   |
| 3    | Adult Mortality             |
| 5    | %Expenditure on Healthcare  |
| 6    | Thinness 1-19 years         |

Interpreting the results above, it is clear that Developing countries that are undergoing an HIV epidemic have the lowest life expectancy of all countries. Eradicating HIV/AIDs should greatly boost the life expectancy of countries that are suffering from this epidemic. After HIV/AIDS, immunization is the next best indicator of life expectancy. This makes intuitive sense. Surprisingly, Schooling is also an extremely important predictor of life expectancy. This is definitely feels like it is not causation. It makes intuitive sense that countries with high life expectancy have higher rates of educational attainment since the populations of those countries are less preoccupied with survival. % Expenditure of GDP on healthcare is also another extremely important metric to explain the variability in life expectancy that we have observed. And lastly, prevalence of thinness is also an extremely important predictor. This also makes intuitive sense and countries with a high prevalence of thinness would be served well by eradicating hunger.

Interestingly, the Developed status of a country nor its GDP are within the top few predictors of life expectancy. 

But the important variables are all definitely correlated with GDP and the developed status of a nation.
Using our simple model to rank models by number of variables has provided us interesting insight into what are the most important factors for governments of countries to be focused on, in order to improve the life expectancy of their people!


# Appendix

## Group Members

| Name            | NetID    |
|-----------------|----------|
| Xinlei Huang    | xhuang84 |
| Mohammad Khan   | mfkahn5  |
| Jaccob Mau      | jcmau2   |
| Jonathan Temkin | jtemkin3 |
